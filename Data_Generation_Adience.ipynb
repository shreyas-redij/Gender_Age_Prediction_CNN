{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYMAsCVlSX7h"
   },
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjMcTgkrSX7i"
   },
   "outputs": [],
   "source": [
    "import h5py, cv2, os, random, argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppk3dKfJSX7n"
   },
   "source": [
    "### Converting the Adience dataset to H5 file and creating train/test split \n",
    "\n",
    "We are using Adience Dataset which contains following information.\n",
    "\n",
    "Statistics and info\n",
    "Total number of photos: 26,580\n",
    "Total number of subjects: 2,284\n",
    "Number of age groups / labels: 8 (0-2, 4-6, 8-13, 15-20, 25-32, 38-43, 48-53, 60-)\n",
    "Gender labels: Yes\n",
    "In the wild: Yes\n",
    "Subject labels: Yes\n",
    "\n",
    "For our project we are taking only gender labels for our images and storing it as a h5 files.\n",
    "\n",
    "We split the data keeping 95% for training and 5% for training and then store them into an H5 file\n",
    "\n",
    "Also, for future use we are taking care of incorrect age Labels. We now have 12 classes as compared to the original 4 classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHXpGor7SX7n"
   },
   "outputs": [],
   "source": [
    "class Process:\n",
    "\n",
    "    def __init__(self, data_path=None, filename=None):\n",
    "        self.filename = filename\n",
    "        self.data_path = data_path\n",
    "        self.prefix = \"landmark_aligned_face.\"  # every image name is prefixed with this string\n",
    "\n",
    "        # 5 folders to loop over, each folder text file contains information of other folders\n",
    "        self.folder_files = ['fold_0_data.txt', 'fold_1_data.txt', 'fold_2_data.txt', 'fold_3_data.txt',\n",
    "                             'fold_4_data.txt']\n",
    "\n",
    "        # age category classes, there are 12 age groups\n",
    "        self.ages = [\"(0, 2)\", \"(4, 6)\", \"(8, 12)\", \"(15, 20)\", \"(21, 24)\", \"(25, 32)\",\n",
    "                     \"(33, 37)\", \"(38, 43)\", \"(44, 47)\", \"(48, 53)\", \"(54, 59)\", \"(60, 100)\"]\n",
    "\n",
    "        # there are only 2 gender categories\n",
    "        self.genders = ['m', 'f']\n",
    "\n",
    "        # Since there are labels that do not match the classes stated, need to fix them\n",
    "        self.ages_to_fix = {'35': self.ages[6], '3': self.ages[0], '55': self.ages[10], '58': self.ages[10],\n",
    "                            '22': self.ages[4], '13': self.ages[2], '45': self.ages[8], '36': self.ages[6],\n",
    "                            '23': self.ages[4], '57': self.ages[10], '56': self.ages[10], '2': self.ages[0],\n",
    "                            '29': self.ages[5], '34': self.ages[6], '42': self.ages[7], '46': self.ages[8],\n",
    "                            '32': self.ages[5], '(38, 48)': self.ages[7], '(38, 42)': self.ages[7],\n",
    "                            '(8, 23)': self.ages[2], '(27, 32)': self.ages[5]}\n",
    "\n",
    "        self.none_count = 0\n",
    "        self.no_age = 0\n",
    "\n",
    "    def get_image_paths(self, folder_file):\n",
    "\n",
    "        # one big folder list\n",
    "        folder = list()\n",
    "        folder_path = os.path.join(self.data_path, folder_file)\n",
    "\n",
    "        # start processing each folder text file\n",
    "        with open(folder_path) as text:\n",
    "            lines = text.readlines()\n",
    "            print(\"Total lines to be parsed from this document: \", len(lines))\n",
    "\n",
    "            # loop over all the lines ignoring the first line which contains metadata of the file contents\n",
    "            for line in lines[1:]:\n",
    "                line = line.strip().split(\"\\t\")  # strip tab character from each line\n",
    "\n",
    "                # line[0] contains folder name, line[2] gives information of image id, line[1] gives exact image name\n",
    "                # construct image path with above information\n",
    "                img_path = line[0] + \"/\" + self.prefix + line[2] + \".\" + line[1]  # real image path\n",
    "                #print(img_path)\n",
    "                # if the age group is not provided, and it is None, then increment None counter and continue to next\n",
    "                # image. Likewise, check if the gender is provided or not, if not then just continue\n",
    "                if line[3] == \"None\":\n",
    "                    self.none_count += 1\n",
    "                    continue\n",
    "\n",
    "                if line[4] == \"u\" or line[4] == \"\":\n",
    "                    self.no_age += 1\n",
    "                    continue\n",
    "\n",
    "                # We store useful metadata infos. for every right image, append the image along with\n",
    "                folder.append([img_path] + line[3:5])\n",
    "                if folder[-1][1] in self.ages_to_fix:\n",
    "                    folder[-1][1] = self.ages_to_fix[folder[-1][1]]\n",
    "\n",
    "        random.shuffle(folder)\n",
    "\n",
    "        return folder\n",
    "\n",
    "    def imread(self, path, width, height):\n",
    "        #print(path)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "        return img\n",
    "\n",
    "    def aggregate_data(self, all_folders):\n",
    "\n",
    "        width, height = 227, 227\n",
    "\n",
    "        # loop for reading imgs from five folders\n",
    "        all_data = []\n",
    "        all_ages = []\n",
    "        all_genders = []\n",
    "        print(\"Start reading images data...\")\n",
    "        for ind, folder in enumerate(all_folders):\n",
    "            data = []\n",
    "            ages = []\n",
    "            genders = []\n",
    "            p\n",
    "            for i in tqdm(range(len(folder))):  # here using tqdm to monitor progress\n",
    "                img_path = self.data_path + os.path.join(\"/aligned/\", folder[i][0])\n",
    "                #print(self.data_path)\n",
    "                #print(img_path)\n",
    "                \n",
    "                isFile = os.path.isfile(img_path) \n",
    "                if(isFile):\n",
    "                    img = self.imread(img_path, width, height)\n",
    "                    data.append(img)\n",
    "                    ages.append(self.ages.index(folder[i][1]))\n",
    "                    genders.append(self.genders.index(folder[i][2]))\n",
    "            all_data.append(data)\n",
    "            all_ages.append(ages)\n",
    "            all_genders.append(genders)\n",
    "            print(\"Finished processing folder {}\".format(str(ind)))\n",
    "\n",
    "        print(\"All done!\")\n",
    "        all_data = np.concatenate(all_data)\n",
    "        all_ages = np.concatenate(all_ages)\n",
    "        all_genders = np.concatenate(all_genders)\n",
    "        return all_data, all_ages, all_genders\n",
    "\n",
    "    def split_data_from_dirs(self, data, ages, genders, split):\n",
    "        \"\"\"\n",
    "        this function takes in data, labels and % of training data to be used. since % of data for training varies based on\n",
    "        applications we keep that parameter user configurable.\n",
    "        :param data: 4D numpy array of images in (num samples, width, height, channels) format\n",
    "        :param labels: 1D numpy array storing labels for corresponding images\n",
    "        :param split: percentage of data to be used for training\n",
    "        :return:  return the splits of training and testing along with labels\n",
    "        \"\"\"\n",
    "        print(\"Number of images in the training data: {}\".format(str(data.shape[0])))\n",
    "        print(\"Ages/Genders: {}\".format(str(ages.shape)))\n",
    "\n",
    "        # multiply split percentage with total images length and floor the result. Also cast into int, for slicing array\n",
    "        split_factor = int(np.floor(split * data.shape[0]))  # number of images to be kept in training data\n",
    "        print(\"Using {} images for training and {} images for testing!\".format(str(split_factor),\n",
    "                                                                               str(data.shape[0] - split_factor)))\n",
    "        x_train = data[:split_factor, :, :, :].astype(\"float\")\n",
    "        x_test = data[split_factor:, :, :, :].astype(\"float\")\n",
    "        y_train_age = ages[:split_factor]\n",
    "        y_test_age = ages[split_factor:]\n",
    "        y_train_gender = genders[:split_factor]\n",
    "        y_test_gender = genders[split_factor:]\n",
    "\n",
    "        print(\"Training data shape: {}\".format(str(x_train.shape)))\n",
    "        print(\"Testing data shape: {}\".format(str(x_test.shape)))\n",
    "        print(\"Training Age labels shape: {}\".format(str(y_train_age.shape)))\n",
    "        print(\"Testing Age labels shape: {}\".format(str(y_test_age.shape)))\n",
    "        print(\"Training Gender labels shape: {}\".format(str(y_train_gender.shape)))\n",
    "        print(\"Testing Gender labels shape: {}\".format(str(y_test_gender.shape)))\n",
    "\n",
    "        return x_train, x_test, y_train_age, y_test_age, y_train_gender, y_test_gender\n",
    "\n",
    "    def generate_h5(self, Xtr, Xtst, ytr_gen, ytst_gen):\n",
    "        \n",
    "        print(\"Generating H5 file...\")\n",
    "        print(\"Training data shape: {}\".format(str(Xtr.shape)))\n",
    "        print(\"Testing data shape: {}\".format(str(Xtst.shape)))\n",
    "        #print(\"Training Age labels shape: {}\".format(str(ytr_gen.shape)))\n",
    "        #print(\"Testing Age labels shape: {}\".format(str(ytst_gen.shape)))\n",
    "        print(\"Training Gender labels shape: {}\".format(str(ytr_gen.shape)))\n",
    "        print(\"Testing Gender labels shape: {}\".format(str(ytst_gen.shape)))\n",
    "        \n",
    "        \n",
    "       \n",
    "        hf = h5py.File(self.filename, 'w')\n",
    "        hf.create_dataset('x_train', data=Xtr, compression=\"gzip\")\n",
    "        hf.create_dataset('x_test', data=Xtst, compression=\"gzip\")\n",
    "        #hf.create_dataset('y_train_age', data=ytr_age, compression=\"gzip\")\n",
    "        #hf.create_dataset('y_test_age', data=ytst_age, compression=\"gzip\")\n",
    "        hf.create_dataset('y_train_gender', data=ytr_gen, compression=\"gzip\")\n",
    "        hf.create_dataset('y_test_gender', data=ytst_gen, compression=\"gzip\")\n",
    "        hf.close()\n",
    "        print(\"H5 file generated successfully\")\n",
    "\n",
    "    def helper(self):\n",
    "\n",
    "        # looping over all the folder text files to aggregate the image paths\n",
    "        all_folders = []\n",
    "        for folder_file in self.folder_files:\n",
    "            folder = self.get_image_paths(folder_file)\n",
    "            all_folders.append(folder)\n",
    "        # print(\"A sample:\", all_folders[0][0])\n",
    "        print(\"No. of Pics without Age Group Label:\", self.none_count)\n",
    "\n",
    "        # total data received after aggregating\n",
    "        data, ages, genders = self.aggregate_data(all_folders)\n",
    "        print(\"Aggregated data shape: {}\".format(str(data.shape)))\n",
    "        print(\"Aggregated age shape: {}\".format(str(ages.shape)))\n",
    "        print(\"Aggregated genders shape: {}\".format(str(genders.shape)))\n",
    "\n",
    "        # splitting data into training and testing based on percentage. split is amount of training data to be used\n",
    "        split = 0.95\n",
    "        x_train, x_test, y_train_age, y_test_age, y_train_gender, y_test_gender = self.split_data_from_dirs(data, ages,\n",
    "                                                                                                            genders,\n",
    "                                                                                                            split)\n",
    "\n",
    "        # encapsulating data into h5 files\n",
    "        #self.generate_h5(x_train, x_test, y_train_age, y_test_age, y_train_gender, y_test_gender)\n",
    "        self.generate_h5(x_train, x_test, y_train_gender, y_test_gender)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5wn3yKdSX7q",
    "outputId": "a1464bcb-2c5d-4d8a-e178-1e307f680dd0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/3995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines to be parsed from this document:  4485\n",
      "Total lines to be parsed from this document:  3731\n",
      "Total lines to be parsed from this document:  3895\n",
      "Total lines to be parsed from this document:  3447\n",
      "Total lines to be parsed from this document:  3817\n",
      "No. of Pics without Age Group Label: 748\n",
      "Start reading images data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3995/3995 [00:44<00:00, 89.38it/s]\n",
      "  0%|▏                                                                               | 10/3597 [00:00<00:38, 92.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3597/3597 [00:41<00:00, 87.05it/s]\n",
      "  0%|                                                                                 | 4/3124 [00:00<01:34, 32.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3124/3124 [00:34<00:00, 89.93it/s]\n",
      "  0%|▍                                                                              | 16/3291 [00:00<00:24, 132.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3291/3291 [00:36<00:00, 89.47it/s]\n",
      "  0%|▍                                                                              | 17/3445 [00:00<00:24, 138.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3445/3445 [00:37<00:00, 91.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing folder 4\n",
      "All done!\n",
      "Aggregated data shape: (4514, 227, 227, 3)\n",
      "Aggregated age shape: (4514,)\n",
      "Aggregated genders shape: (4514,)\n",
      "Number of images in the training data: 4514\n",
      "Ages/Genders: (4514,)\n",
      "Using 4288 images for training and 226 images for testing!\n",
      "Training data shape: (4288, 227, 227, 3)\n",
      "Testing data shape: (226, 227, 227, 3)\n",
      "Training Age labels shape: (4288,)\n",
      "Testing Age labels shape: (226,)\n",
      "Training Gender labels shape: (4288,)\n",
      "Testing Gender labels shape: (226,)\n",
      "Generating H5 file...\n",
      "Training data shape: (4288, 227, 227, 3)\n",
      "Testing data shape: (226, 227, 227, 3)\n",
      "Training Gender labels shape: (4288,)\n",
      "Testing Gender labels shape: (226,)\n",
      "H5 file generated successfully\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path=\"data/adience\"\n",
    "    save=\"adience_1.h5\"\n",
    "    p = Process(path, save)\n",
    "    p.helper()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Generation_Adience.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
